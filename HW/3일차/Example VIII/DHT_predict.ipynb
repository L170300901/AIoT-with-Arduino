{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRkchwxIxLOY"
      },
      "source": [
        "# DHT22 Prediction Model\n",
        "\n",
        "아래 중간 중간 `#빈칸`을 채우며 적절히 설계해보세요. 끝까지 실행하면 `temp_predict.onnx` 및 `humi_predict.onnx` 파일이 생성됩니다."
      ],
      "id": "PRkchwxIxLOY"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B4q1buloxLOd"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.onnx\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "id": "B4q1buloxLOd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FZpw4U4xLOf"
      },
      "source": [
        "### Class Definitions"
      ],
      "id": "4FZpw4U4xLOf"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8xrxDMNwxLOg"
      },
      "outputs": [],
      "source": [
        "class DHTDataset(Dataset):\n",
        "    def __init__(self, key):\n",
        "        self.data = []\n",
        "        self.target = []\n",
        "        self.key = key\n",
        "\n",
        "        db = open(\"db.json\", \"r\")\n",
        "        humi_temp = json.load(db)\n",
        "\n",
        "        for i in range(len(humi_temp.get(self.key))-62):\n",
        "            tmp_data = []\n",
        "            tmp_data.append([float(humi_temp.get(self.key)[i][1])])\n",
        "            tmp_data.append([float(humi_temp.get(self.key)[i+1][1])])\n",
        "            tmp_data.append([float(humi_temp.get(self.key)[i+2][1])])\n",
        "            self.data.append(torch.as_tensor(tmp_data))\n",
        "\n",
        "            self.target.append(\n",
        "                torch.as_tensor([float(humi_temp.get(self.key)[i+62][1])]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        data, target = self.data[index], self.target[index]\n",
        "        return data, target"
      ],
      "id": "8xrxDMNwxLOg"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "6655fbbd",
      "metadata": {
        "id": "6655fbbd"
      },
      "outputs": [],
      "source": [
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleModel, self).__init__()\n",
        "\n",
        "        self.linear = nn.Sequential(\n",
        "           nn.Linear(3,1)\n",
        "        )\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x.squeeze())\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3bba4f6",
      "metadata": {
        "id": "b3bba4f6"
      },
      "source": [
        "### Function Definitions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3460f0c0",
      "metadata": {
        "id": "3460f0c0"
      },
      "source": [
        "##### A function to split dataset into several data loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "a92d7b1d",
      "metadata": {
        "id": "a92d7b1d"
      },
      "outputs": [],
      "source": [
        "def splitDataset(dataset):\n",
        "    test_size = int(len(dataset)/6)\n",
        "    val_size = int(len(dataset)/6)\n",
        "    train_size = len(dataset) - test_size - val_size\n",
        "\n",
        "    trainset, valset, testset = torch.utils.data.random_split(\n",
        "        dataset, [train_size, val_size, test_size])\n",
        "\n",
        "    trainloader = DataLoader(trainset, batch_size=16, shuffle=True)\n",
        "    validloader = DataLoader(valset, batch_size=16, shuffle=True)\n",
        "    testloader = DataLoader(testset, batch_size=16, shuffle=True)\n",
        "\n",
        "    return trainloader, validloader, testloader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "610be662",
      "metadata": {
        "id": "610be662"
      },
      "source": [
        "##### A function to train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "828d4386",
      "metadata": {
        "id": "828d4386"
      },
      "outputs": [],
      "source": [
        "def train_model(model, patience, num_epochs, train_loader, valid_loader):\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "    mean_train_losses = []\n",
        "    mean_valid_losses = []\n",
        "    p = 0\n",
        "    min_valid_loss = float(\"inf\")\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "\n",
        "        model.train()\n",
        "        for train_data, train_target in train_loader:\n",
        "            if torch.cuda.is_available():\n",
        "                device = torch.device(\"cuda\")\n",
        "                train_data = train_data.to(device, dtype=torch.float)\n",
        "                train_target = train_target.to(device, dtype=torch.float)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(train_data)\n",
        "            loss = criterion(output, train_target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        for valid_data, valid_target in valid_loader:\n",
        "            if torch.cuda.is_available():\n",
        "                device = torch.device(\"cuda\")\n",
        "                valid_data = valid_data.to(device, dtype=torch.float)\n",
        "                valid_target = valid_target.to(device, dtype=torch.float)\n",
        "            output = model(valid_data)\n",
        "            loss = criterion(output, valid_target)\n",
        "            valid_losses.append(loss.item())\n",
        "\n",
        "        train_loss = np.mean(train_losses)\n",
        "        valid_loss = np.mean(valid_losses)\n",
        "        mean_train_losses.append(train_loss)\n",
        "        mean_valid_losses.append(valid_loss)\n",
        "\n",
        "        if min_valid_loss > valid_loss:\n",
        "            min_valid_loss = valid_loss\n",
        "            print(f\"min_valid_loss: {min_valid_loss}\")\n",
        "\n",
        "        epoch_len = len(str(num_epochs))\n",
        "        print_msg = (f\"[{epoch:>{epoch_len}}/{num_epochs:>{epoch_len}}] \" +\n",
        "                     f\"train_loss: {train_loss:.5f} \" +\n",
        "                     f\"valid_loss: {valid_loss:.5f} \")\n",
        "        print(print_msg)\n",
        "\n",
        "        train_losses = []\n",
        "        valid_losses = []\n",
        "\n",
        "        if min_valid_loss < valid_loss and epoch > 1:\n",
        "            p = p + 1\n",
        "            print(f'patience: {p}')\n",
        "        else:\n",
        "            p = 0\n",
        "            torch.save(model.state_dict(), \"bestmodel.pt\")\n",
        "            print(\"Saving Model...\")\n",
        "\n",
        "        if patience == p:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "\n",
        "    model.load_state_dict(torch.load(\"bestmodel.pt\"))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83317dae",
      "metadata": {
        "id": "83317dae"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwjPhRxNxLOn"
      },
      "source": [
        "##### Load datasets and get dataloaders"
      ],
      "id": "ZwjPhRxNxLOn"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "HaiomMwIxLOo"
      },
      "outputs": [],
      "source": [
        "tempDataset = DHTDataset(\"temperature\")\n",
        "humiDataset = DHTDataset(\"humidity\")\n",
        "\n",
        "temp_trainloader, temp_validloader, temp_testloader = splitDataset(tempDataset)\n",
        "humi_trainloader, humi_validloader, humi_testloader = splitDataset(humiDataset)"
      ],
      "id": "HaiomMwIxLOo"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8V39AD7oxLOo"
      },
      "source": [
        "##### Make models"
      ],
      "id": "8V39AD7oxLOo"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "1f4y21QgxLOp"
      },
      "outputs": [],
      "source": [
        "tempModel = SimpleModel()\n",
        "humiModel = SimpleModel()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    tempModel = tempModel.cuda()\n",
        "    humiModel = humiModel.cuda()"
      ],
      "id": "1f4y21QgxLOp"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19v2ZEXRxLOp"
      },
      "source": [
        "##### Do training with earlystopping"
      ],
      "id": "19v2ZEXRxLOp"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2ao_f0_xLOp",
        "outputId": "16279152-cd18-4b4c-9cdd-bc7eaf4da0c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "min_valid_loss: 2.6229708796148903\n",
            "[   1/1000] train_loss: 123.47335 valid_loss: 2.62297 \n",
            "Saving Model...\n",
            "min_valid_loss: 0.003266205022563562\n",
            "[   2/1000] train_loss: 0.32901 valid_loss: 0.00327 \n",
            "Saving Model...\n",
            "min_valid_loss: 0.0031735118757112374\n",
            "[   3/1000] train_loss: 0.00348 valid_loss: 0.00317 \n",
            "Saving Model...\n",
            "[   4/1000] train_loss: 0.00346 valid_loss: 0.00318 \n",
            "patience: 1\n",
            "[   5/1000] train_loss: 0.00346 valid_loss: 0.00321 \n",
            "patience: 2\n",
            "[   6/1000] train_loss: 0.00346 valid_loss: 0.00320 \n",
            "patience: 3\n",
            "[   7/1000] train_loss: 0.00346 valid_loss: 0.00318 \n",
            "patience: 4\n",
            "[   8/1000] train_loss: 0.00348 valid_loss: 0.00317 \n",
            "patience: 5\n",
            "[   9/1000] train_loss: 0.00346 valid_loss: 0.00319 \n",
            "patience: 6\n",
            "[  10/1000] train_loss: 0.00348 valid_loss: 0.00318 \n",
            "patience: 7\n",
            "[  11/1000] train_loss: 0.00347 valid_loss: 0.00321 \n",
            "patience: 8\n",
            "[  12/1000] train_loss: 0.00347 valid_loss: 0.00322 \n",
            "patience: 9\n",
            "[  13/1000] train_loss: 0.00348 valid_loss: 0.00318 \n",
            "patience: 10\n",
            "min_valid_loss: 0.003154915492167027\n",
            "[  14/1000] train_loss: 0.00348 valid_loss: 0.00315 \n",
            "Saving Model...\n",
            "[  15/1000] train_loss: 0.00348 valid_loss: 0.00320 \n",
            "patience: 1\n",
            "[  16/1000] train_loss: 0.00349 valid_loss: 0.00319 \n",
            "patience: 2\n",
            "[  17/1000] train_loss: 0.00350 valid_loss: 0.00319 \n",
            "patience: 3\n",
            "[  18/1000] train_loss: 0.00350 valid_loss: 0.00316 \n",
            "patience: 4\n",
            "[  19/1000] train_loss: 0.00350 valid_loss: 0.00328 \n",
            "patience: 5\n",
            "[  20/1000] train_loss: 0.00355 valid_loss: 0.00323 \n",
            "patience: 6\n",
            "[  21/1000] train_loss: 0.00355 valid_loss: 0.00319 \n",
            "patience: 7\n",
            "[  22/1000] train_loss: 0.00359 valid_loss: 0.00328 \n",
            "patience: 8\n",
            "[  23/1000] train_loss: 0.00368 valid_loss: 0.00317 \n",
            "patience: 9\n",
            "[  24/1000] train_loss: 0.00372 valid_loss: 0.00456 \n",
            "patience: 10\n",
            "[  25/1000] train_loss: 0.00374 valid_loss: 0.00352 \n",
            "patience: 11\n",
            "[  26/1000] train_loss: 0.00371 valid_loss: 0.00413 \n",
            "patience: 12\n",
            "[  27/1000] train_loss: 0.00385 valid_loss: 0.00323 \n",
            "patience: 13\n",
            "[  28/1000] train_loss: 0.00389 valid_loss: 0.00389 \n",
            "patience: 14\n",
            "[  29/1000] train_loss: 0.00379 valid_loss: 0.00321 \n",
            "patience: 15\n",
            "[  30/1000] train_loss: 0.00384 valid_loss: 0.00321 \n",
            "patience: 16\n",
            "[  31/1000] train_loss: 0.00402 valid_loss: 0.00325 \n",
            "patience: 17\n",
            "[  32/1000] train_loss: 0.00388 valid_loss: 0.00340 \n",
            "patience: 18\n",
            "[  33/1000] train_loss: 0.00382 valid_loss: 0.00335 \n",
            "patience: 19\n",
            "[  34/1000] train_loss: 0.00383 valid_loss: 0.00414 \n",
            "patience: 20\n",
            "[  35/1000] train_loss: 0.00373 valid_loss: 0.00373 \n",
            "patience: 21\n",
            "[  36/1000] train_loss: 0.00393 valid_loss: 0.00330 \n",
            "patience: 22\n",
            "[  37/1000] train_loss: 0.00390 valid_loss: 0.00686 \n",
            "patience: 23\n",
            "[  38/1000] train_loss: 0.00401 valid_loss: 0.00417 \n",
            "patience: 24\n",
            "[  39/1000] train_loss: 0.00380 valid_loss: 0.00385 \n",
            "patience: 25\n",
            "[  40/1000] train_loss: 0.00385 valid_loss: 0.00385 \n",
            "patience: 26\n",
            "[  41/1000] train_loss: 0.00390 valid_loss: 0.00329 \n",
            "patience: 27\n",
            "[  42/1000] train_loss: 0.00381 valid_loss: 0.00374 \n",
            "patience: 28\n",
            "[  43/1000] train_loss: 0.00388 valid_loss: 0.00332 \n",
            "patience: 29\n",
            "[  44/1000] train_loss: 0.00377 valid_loss: 0.00506 \n",
            "patience: 30\n",
            "Early stopping\n"
          ]
        }
      ],
      "source": [
        "temp_predict_model = train_model(tempModel, patience=30, num_epochs=1000,\n",
        "                                 train_loader=temp_trainloader,\n",
        "                                 valid_loader=temp_validloader)\n",
        "torch.save(temp_predict_model.state_dict(), \"temp_predict.pt\")"
      ],
      "id": "p2ao_f0_xLOp"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PT48wdZoxLOq",
        "outputId": "5dbe9367-1650-4924-8eae-7420c973012d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "min_valid_loss: 142.12180486455694\n",
            "[   1/1000] train_loss: 987.97827 valid_loss: 142.12180 \n",
            "Saving Model...\n",
            "min_valid_loss: 1.0482591181188017\n",
            "[   2/1000] train_loss: 33.04656 valid_loss: 1.04826 \n",
            "Saving Model...\n",
            "min_valid_loss: 0.07599061453161207\n",
            "[   3/1000] train_loss: 0.39506 valid_loss: 0.07599 \n",
            "Saving Model...\n",
            "min_valid_loss: 0.07506937923765666\n",
            "[   4/1000] train_loss: 0.24641 valid_loss: 0.07507 \n",
            "Saving Model...\n",
            "min_valid_loss: 0.0750012493876925\n",
            "[   5/1000] train_loss: 0.24641 valid_loss: 0.07500 \n",
            "Saving Model...\n",
            "[   6/1000] train_loss: 0.24642 valid_loss: 0.07500 \n",
            "patience: 1\n",
            "min_valid_loss: 0.07495552716572346\n",
            "[   7/1000] train_loss: 0.24651 valid_loss: 0.07496 \n",
            "Saving Model...\n",
            "[   8/1000] train_loss: 0.24656 valid_loss: 0.07608 \n",
            "patience: 1\n",
            "[   9/1000] train_loss: 0.24640 valid_loss: 0.07510 \n",
            "patience: 2\n",
            "[  10/1000] train_loss: 0.24684 valid_loss: 0.07544 \n",
            "patience: 3\n",
            "[  11/1000] train_loss: 0.24695 valid_loss: 0.07521 \n",
            "patience: 4\n",
            "[  12/1000] train_loss: 0.24704 valid_loss: 0.07508 \n",
            "patience: 5\n",
            "[  13/1000] train_loss: 0.24674 valid_loss: 0.07499 \n",
            "patience: 6\n",
            "[  14/1000] train_loss: 0.24740 valid_loss: 0.07543 \n",
            "patience: 7\n",
            "[  15/1000] train_loss: 0.24762 valid_loss: 0.07517 \n",
            "patience: 8\n",
            "[  16/1000] train_loss: 0.24814 valid_loss: 0.07848 \n",
            "patience: 9\n",
            "[  17/1000] train_loss: 0.24727 valid_loss: 0.07818 \n",
            "patience: 10\n",
            "[  18/1000] train_loss: 0.24900 valid_loss: 0.08400 \n",
            "patience: 11\n",
            "[  19/1000] train_loss: 0.24797 valid_loss: 0.07913 \n",
            "patience: 12\n",
            "[  20/1000] train_loss: 0.24924 valid_loss: 0.08147 \n",
            "patience: 13\n",
            "[  21/1000] train_loss: 0.24970 valid_loss: 0.08155 \n",
            "patience: 14\n",
            "[  22/1000] train_loss: 0.25001 valid_loss: 0.07497 \n",
            "patience: 15\n",
            "[  23/1000] train_loss: 0.25078 valid_loss: 0.07967 \n",
            "patience: 16\n",
            "[  24/1000] train_loss: 0.25107 valid_loss: 0.07557 \n",
            "patience: 17\n",
            "[  25/1000] train_loss: 0.24984 valid_loss: 0.07500 \n",
            "patience: 18\n",
            "[  26/1000] train_loss: 0.25075 valid_loss: 0.07571 \n",
            "patience: 19\n",
            "[  27/1000] train_loss: 0.25314 valid_loss: 0.07614 \n",
            "patience: 20\n",
            "[  28/1000] train_loss: 0.25286 valid_loss: 0.07554 \n",
            "patience: 21\n",
            "[  29/1000] train_loss: 0.25265 valid_loss: 0.07714 \n",
            "patience: 22\n",
            "[  30/1000] train_loss: 0.25430 valid_loss: 0.07824 \n",
            "patience: 23\n",
            "[  31/1000] train_loss: 0.25170 valid_loss: 0.07629 \n",
            "patience: 24\n",
            "[  32/1000] train_loss: 0.25166 valid_loss: 0.08533 \n",
            "patience: 25\n",
            "[  33/1000] train_loss: 0.25304 valid_loss: 0.07809 \n",
            "patience: 26\n",
            "[  34/1000] train_loss: 0.25230 valid_loss: 0.08971 \n",
            "patience: 27\n",
            "min_valid_loss: 0.07480356119036137\n",
            "[  35/1000] train_loss: 0.25280 valid_loss: 0.07480 \n",
            "Saving Model...\n",
            "[  36/1000] train_loss: 0.25198 valid_loss: 0.10835 \n",
            "patience: 1\n",
            "[  37/1000] train_loss: 0.25283 valid_loss: 0.10538 \n",
            "patience: 2\n",
            "[  38/1000] train_loss: 0.25255 valid_loss: 0.07525 \n",
            "patience: 3\n",
            "[  39/1000] train_loss: 0.25182 valid_loss: 0.08600 \n",
            "patience: 4\n",
            "[  40/1000] train_loss: 0.25142 valid_loss: 0.08456 \n",
            "patience: 5\n",
            "min_valid_loss: 0.0746250336770564\n",
            "[  41/1000] train_loss: 0.25201 valid_loss: 0.07463 \n",
            "Saving Model...\n",
            "[  42/1000] train_loss: 0.25380 valid_loss: 0.10111 \n",
            "patience: 1\n",
            "[  43/1000] train_loss: 0.25466 valid_loss: 0.11269 \n",
            "patience: 2\n",
            "[  44/1000] train_loss: 0.25250 valid_loss: 0.08770 \n",
            "patience: 3\n",
            "[  45/1000] train_loss: 0.25029 valid_loss: 0.07466 \n",
            "patience: 4\n",
            "[  46/1000] train_loss: 0.25333 valid_loss: 0.10220 \n",
            "patience: 5\n",
            "[  47/1000] train_loss: 0.25163 valid_loss: 0.08918 \n",
            "patience: 6\n",
            "[  48/1000] train_loss: 0.25183 valid_loss: 0.08190 \n",
            "patience: 7\n",
            "[  49/1000] train_loss: 0.25683 valid_loss: 0.09705 \n",
            "patience: 8\n",
            "[  50/1000] train_loss: 0.25450 valid_loss: 0.07594 \n",
            "patience: 9\n",
            "[  51/1000] train_loss: 0.24976 valid_loss: 0.12332 \n",
            "patience: 10\n",
            "[  52/1000] train_loss: 0.24961 valid_loss: 0.07541 \n",
            "patience: 11\n",
            "[  53/1000] train_loss: 0.24895 valid_loss: 0.09561 \n",
            "patience: 12\n",
            "[  54/1000] train_loss: 0.25258 valid_loss: 0.07639 \n",
            "patience: 13\n",
            "[  55/1000] train_loss: 0.24992 valid_loss: 0.07474 \n",
            "patience: 14\n",
            "[  56/1000] train_loss: 0.25306 valid_loss: 0.07498 \n",
            "patience: 15\n",
            "min_valid_loss: 0.0745146129131401\n",
            "[  57/1000] train_loss: 0.24913 valid_loss: 0.07451 \n",
            "Saving Model...\n",
            "[  58/1000] train_loss: 0.24982 valid_loss: 0.08336 \n",
            "patience: 1\n",
            "[  59/1000] train_loss: 0.25179 valid_loss: 0.08741 \n",
            "patience: 2\n",
            "[  60/1000] train_loss: 0.25198 valid_loss: 0.08169 \n",
            "patience: 3\n",
            "[  61/1000] train_loss: 0.25175 valid_loss: 0.07699 \n",
            "patience: 4\n",
            "[  62/1000] train_loss: 0.24995 valid_loss: 0.07583 \n",
            "patience: 5\n",
            "[  63/1000] train_loss: 0.25094 valid_loss: 0.07480 \n",
            "patience: 6\n",
            "[  64/1000] train_loss: 0.25207 valid_loss: 0.08616 \n",
            "patience: 7\n",
            "[  65/1000] train_loss: 0.25008 valid_loss: 0.07769 \n",
            "patience: 8\n",
            "[  66/1000] train_loss: 0.25337 valid_loss: 0.07683 \n",
            "patience: 9\n",
            "[  67/1000] train_loss: 0.24934 valid_loss: 0.08332 \n",
            "patience: 10\n",
            "[  68/1000] train_loss: 0.24989 valid_loss: 0.09422 \n",
            "patience: 11\n",
            "[  69/1000] train_loss: 0.25005 valid_loss: 0.08444 \n",
            "patience: 12\n",
            "min_valid_loss: 0.07434211763645615\n",
            "[  70/1000] train_loss: 0.25142 valid_loss: 0.07434 \n",
            "Saving Model...\n",
            "[  71/1000] train_loss: 0.25259 valid_loss: 0.07681 \n",
            "patience: 1\n",
            "[  72/1000] train_loss: 0.25248 valid_loss: 0.07444 \n",
            "patience: 2\n",
            "[  73/1000] train_loss: 0.24952 valid_loss: 0.07515 \n",
            "patience: 3\n",
            "[  74/1000] train_loss: 0.24905 valid_loss: 0.09327 \n",
            "patience: 4\n",
            "[  75/1000] train_loss: 0.24946 valid_loss: 0.09912 \n",
            "patience: 5\n",
            "[  76/1000] train_loss: 0.25014 valid_loss: 0.07775 \n",
            "patience: 6\n",
            "[  77/1000] train_loss: 0.25154 valid_loss: 0.07526 \n",
            "patience: 7\n",
            "[  78/1000] train_loss: 0.25031 valid_loss: 0.08487 \n",
            "patience: 8\n",
            "[  79/1000] train_loss: 0.25235 valid_loss: 0.07791 \n",
            "patience: 9\n",
            "min_valid_loss: 0.07416125879044065\n",
            "[  80/1000] train_loss: 0.25000 valid_loss: 0.07416 \n",
            "Saving Model...\n",
            "[  81/1000] train_loss: 0.24701 valid_loss: 0.07803 \n",
            "patience: 1\n",
            "[  82/1000] train_loss: 0.25049 valid_loss: 0.07507 \n",
            "patience: 2\n",
            "[  83/1000] train_loss: 0.24899 valid_loss: 0.08800 \n",
            "patience: 3\n",
            "[  84/1000] train_loss: 0.25169 valid_loss: 0.07417 \n",
            "patience: 4\n",
            "[  85/1000] train_loss: 0.25077 valid_loss: 0.07529 \n",
            "patience: 5\n",
            "[  86/1000] train_loss: 0.24971 valid_loss: 0.09294 \n",
            "patience: 6\n",
            "[  87/1000] train_loss: 0.25233 valid_loss: 0.08154 \n",
            "patience: 7\n",
            "[  88/1000] train_loss: 0.25037 valid_loss: 0.07571 \n",
            "patience: 8\n",
            "[  89/1000] train_loss: 0.25001 valid_loss: 0.07416 \n",
            "patience: 9\n",
            "[  90/1000] train_loss: 0.25232 valid_loss: 0.09687 \n",
            "patience: 10\n",
            "[  91/1000] train_loss: 0.25149 valid_loss: 0.08211 \n",
            "patience: 11\n",
            "min_valid_loss: 0.07399666483874794\n",
            "[  92/1000] train_loss: 0.25047 valid_loss: 0.07400 \n",
            "Saving Model...\n",
            "[  93/1000] train_loss: 0.25053 valid_loss: 0.09050 \n",
            "patience: 1\n",
            "[  94/1000] train_loss: 0.25036 valid_loss: 0.11852 \n",
            "patience: 2\n",
            "min_valid_loss: 0.07398666779149894\n",
            "[  95/1000] train_loss: 0.24991 valid_loss: 0.07399 \n",
            "Saving Model...\n",
            "[  96/1000] train_loss: 0.24924 valid_loss: 0.08404 \n",
            "patience: 1\n",
            "[  97/1000] train_loss: 0.24990 valid_loss: 0.07511 \n",
            "patience: 2\n",
            "[  98/1000] train_loss: 0.24962 valid_loss: 0.07428 \n",
            "patience: 3\n",
            "[  99/1000] train_loss: 0.25313 valid_loss: 0.07550 \n",
            "patience: 4\n",
            "[ 100/1000] train_loss: 0.24740 valid_loss: 0.07864 \n",
            "patience: 5\n",
            "[ 101/1000] train_loss: 0.24897 valid_loss: 0.10103 \n",
            "patience: 6\n",
            "[ 102/1000] train_loss: 0.24972 valid_loss: 0.09753 \n",
            "patience: 7\n",
            "[ 103/1000] train_loss: 0.24730 valid_loss: 0.08302 \n",
            "patience: 8\n",
            "[ 104/1000] train_loss: 0.24849 valid_loss: 0.07576 \n",
            "patience: 9\n",
            "[ 105/1000] train_loss: 0.24749 valid_loss: 0.07633 \n",
            "patience: 10\n",
            "[ 106/1000] train_loss: 0.24820 valid_loss: 0.12648 \n",
            "patience: 11\n",
            "[ 107/1000] train_loss: 0.24848 valid_loss: 0.07505 \n",
            "patience: 12\n",
            "[ 108/1000] train_loss: 0.24979 valid_loss: 0.08055 \n",
            "patience: 13\n",
            "min_valid_loss: 0.07381448608630144\n",
            "[ 109/1000] train_loss: 0.25041 valid_loss: 0.07381 \n",
            "Saving Model...\n",
            "[ 110/1000] train_loss: 0.25058 valid_loss: 0.07496 \n",
            "patience: 1\n",
            "[ 111/1000] train_loss: 0.25028 valid_loss: 0.08223 \n",
            "patience: 2\n",
            "[ 112/1000] train_loss: 0.25030 valid_loss: 0.07411 \n",
            "patience: 3\n",
            "[ 113/1000] train_loss: 0.24860 valid_loss: 0.08747 \n",
            "patience: 4\n",
            "[ 114/1000] train_loss: 0.24999 valid_loss: 0.10730 \n",
            "patience: 5\n",
            "min_valid_loss: 0.07372137485911046\n",
            "[ 115/1000] train_loss: 0.24969 valid_loss: 0.07372 \n",
            "Saving Model...\n",
            "[ 116/1000] train_loss: 0.25082 valid_loss: 0.08152 \n",
            "patience: 1\n",
            "[ 117/1000] train_loss: 0.24906 valid_loss: 0.08312 \n",
            "patience: 2\n",
            "[ 118/1000] train_loss: 0.24724 valid_loss: 0.07564 \n",
            "patience: 3\n",
            "[ 119/1000] train_loss: 0.24914 valid_loss: 0.07413 \n",
            "patience: 4\n",
            "[ 120/1000] train_loss: 0.24782 valid_loss: 0.07530 \n",
            "patience: 5\n",
            "[ 121/1000] train_loss: 0.24945 valid_loss: 0.07532 \n",
            "patience: 6\n",
            "[ 122/1000] train_loss: 0.24875 valid_loss: 0.07470 \n",
            "patience: 7\n",
            "[ 123/1000] train_loss: 0.24853 valid_loss: 0.07811 \n",
            "patience: 8\n",
            "[ 124/1000] train_loss: 0.24841 valid_loss: 0.09284 \n",
            "patience: 9\n",
            "[ 125/1000] train_loss: 0.24772 valid_loss: 0.07586 \n",
            "patience: 10\n",
            "[ 126/1000] train_loss: 0.24866 valid_loss: 0.07482 \n",
            "patience: 11\n",
            "[ 127/1000] train_loss: 0.24783 valid_loss: 0.07471 \n",
            "patience: 12\n",
            "[ 128/1000] train_loss: 0.24730 valid_loss: 0.07424 \n",
            "patience: 13\n",
            "min_valid_loss: 0.07370694268176013\n",
            "[ 129/1000] train_loss: 0.25003 valid_loss: 0.07371 \n",
            "Saving Model...\n",
            "[ 130/1000] train_loss: 0.25085 valid_loss: 0.07449 \n",
            "patience: 1\n",
            "[ 131/1000] train_loss: 0.24830 valid_loss: 0.08080 \n",
            "patience: 2\n",
            "[ 132/1000] train_loss: 0.24683 valid_loss: 0.07495 \n",
            "patience: 3\n",
            "[ 133/1000] train_loss: 0.24947 valid_loss: 0.07816 \n",
            "patience: 4\n",
            "[ 134/1000] train_loss: 0.24819 valid_loss: 0.11776 \n",
            "patience: 5\n",
            "min_valid_loss: 0.07370505802048084\n",
            "[ 135/1000] train_loss: 0.24612 valid_loss: 0.07371 \n",
            "Saving Model...\n",
            "[ 136/1000] train_loss: 0.25108 valid_loss: 0.08375 \n",
            "patience: 1\n",
            "min_valid_loss: 0.07364149132391086\n",
            "[ 137/1000] train_loss: 0.24879 valid_loss: 0.07364 \n",
            "Saving Model...\n",
            "[ 138/1000] train_loss: 0.24929 valid_loss: 0.07445 \n",
            "patience: 1\n",
            "[ 139/1000] train_loss: 0.24776 valid_loss: 0.10468 \n",
            "patience: 2\n",
            "[ 140/1000] train_loss: 0.25053 valid_loss: 0.07690 \n",
            "patience: 3\n",
            "[ 141/1000] train_loss: 0.24633 valid_loss: 0.08062 \n",
            "patience: 4\n",
            "min_valid_loss: 0.07329644486077365\n",
            "[ 142/1000] train_loss: 0.24605 valid_loss: 0.07330 \n",
            "Saving Model...\n",
            "[ 143/1000] train_loss: 0.24723 valid_loss: 0.07645 \n",
            "patience: 1\n",
            "[ 144/1000] train_loss: 0.24700 valid_loss: 0.08041 \n",
            "patience: 2\n",
            "[ 145/1000] train_loss: 0.24833 valid_loss: 0.07870 \n",
            "patience: 3\n",
            "min_valid_loss: 0.07322720263723854\n",
            "[ 146/1000] train_loss: 0.24849 valid_loss: 0.07323 \n",
            "Saving Model...\n",
            "[ 147/1000] train_loss: 0.24632 valid_loss: 0.07336 \n",
            "patience: 1\n",
            "[ 148/1000] train_loss: 0.25013 valid_loss: 0.07349 \n",
            "patience: 2\n",
            "[ 149/1000] train_loss: 0.24808 valid_loss: 0.07330 \n",
            "patience: 3\n",
            "[ 150/1000] train_loss: 0.24507 valid_loss: 0.07878 \n",
            "patience: 4\n",
            "[ 151/1000] train_loss: 0.24757 valid_loss: 0.07616 \n",
            "patience: 5\n",
            "[ 152/1000] train_loss: 0.24743 valid_loss: 0.07373 \n",
            "patience: 6\n",
            "[ 153/1000] train_loss: 0.24683 valid_loss: 0.07722 \n",
            "patience: 7\n",
            "[ 154/1000] train_loss: 0.24959 valid_loss: 0.07738 \n",
            "patience: 8\n",
            "[ 155/1000] train_loss: 0.24687 valid_loss: 0.07445 \n",
            "patience: 9\n",
            "[ 156/1000] train_loss: 0.24602 valid_loss: 0.07892 \n",
            "patience: 10\n",
            "[ 157/1000] train_loss: 0.24616 valid_loss: 0.07667 \n",
            "patience: 11\n",
            "[ 158/1000] train_loss: 0.24770 valid_loss: 0.08670 \n",
            "patience: 12\n",
            "[ 159/1000] train_loss: 0.24714 valid_loss: 0.07325 \n",
            "patience: 13\n",
            "min_valid_loss: 0.07322543373264305\n",
            "[ 160/1000] train_loss: 0.24576 valid_loss: 0.07323 \n",
            "Saving Model...\n",
            "[ 161/1000] train_loss: 0.24658 valid_loss: 0.07592 \n",
            "patience: 1\n",
            "[ 162/1000] train_loss: 0.24860 valid_loss: 0.07442 \n",
            "patience: 2\n",
            "min_valid_loss: 0.07302297033822618\n",
            "[ 163/1000] train_loss: 0.24593 valid_loss: 0.07302 \n",
            "Saving Model...\n",
            "[ 164/1000] train_loss: 0.24744 valid_loss: 0.07362 \n",
            "patience: 1\n",
            "[ 165/1000] train_loss: 0.24609 valid_loss: 0.07894 \n",
            "patience: 2\n",
            "[ 166/1000] train_loss: 0.24627 valid_loss: 0.08451 \n",
            "patience: 3\n",
            "[ 167/1000] train_loss: 0.24608 valid_loss: 0.08811 \n",
            "patience: 4\n",
            "[ 168/1000] train_loss: 0.24715 valid_loss: 0.07449 \n",
            "patience: 5\n",
            "[ 169/1000] train_loss: 0.24809 valid_loss: 0.07683 \n",
            "patience: 6\n",
            "[ 170/1000] train_loss: 0.24699 valid_loss: 0.07863 \n",
            "patience: 7\n",
            "[ 171/1000] train_loss: 0.24554 valid_loss: 0.07887 \n",
            "patience: 8\n",
            "[ 172/1000] train_loss: 0.24418 valid_loss: 0.08144 \n",
            "patience: 9\n",
            "[ 173/1000] train_loss: 0.24633 valid_loss: 0.07573 \n",
            "patience: 10\n",
            "[ 174/1000] train_loss: 0.24579 valid_loss: 0.08071 \n",
            "patience: 11\n",
            "[ 175/1000] train_loss: 0.24578 valid_loss: 0.07574 \n",
            "patience: 12\n",
            "[ 176/1000] train_loss: 0.24952 valid_loss: 0.07324 \n",
            "patience: 13\n",
            "[ 177/1000] train_loss: 0.24429 valid_loss: 0.07304 \n",
            "patience: 14\n",
            "[ 178/1000] train_loss: 0.24794 valid_loss: 0.07533 \n",
            "patience: 15\n",
            "[ 179/1000] train_loss: 0.24443 valid_loss: 0.07769 \n",
            "patience: 16\n",
            "[ 180/1000] train_loss: 0.24614 valid_loss: 0.08358 \n",
            "patience: 17\n",
            "[ 181/1000] train_loss: 0.24441 valid_loss: 0.07407 \n",
            "patience: 18\n",
            "[ 182/1000] train_loss: 0.24841 valid_loss: 0.07471 \n",
            "patience: 19\n",
            "[ 183/1000] train_loss: 0.24346 valid_loss: 0.07733 \n",
            "patience: 20\n",
            "[ 184/1000] train_loss: 0.24476 valid_loss: 0.08263 \n",
            "patience: 21\n",
            "min_valid_loss: 0.07289468442920495\n",
            "[ 185/1000] train_loss: 0.24789 valid_loss: 0.07289 \n",
            "Saving Model...\n",
            "[ 186/1000] train_loss: 0.24492 valid_loss: 0.08994 \n",
            "patience: 1\n",
            "[ 187/1000] train_loss: 0.24573 valid_loss: 0.07470 \n",
            "patience: 2\n",
            "[ 188/1000] train_loss: 0.24613 valid_loss: 0.10520 \n",
            "patience: 3\n",
            "[ 189/1000] train_loss: 0.24733 valid_loss: 0.07719 \n",
            "patience: 4\n",
            "[ 190/1000] train_loss: 0.24713 valid_loss: 0.08472 \n",
            "patience: 5\n",
            "[ 191/1000] train_loss: 0.24565 valid_loss: 0.07777 \n",
            "patience: 6\n",
            "[ 192/1000] train_loss: 0.24430 valid_loss: 0.07293 \n",
            "patience: 7\n",
            "[ 193/1000] train_loss: 0.24728 valid_loss: 0.07452 \n",
            "patience: 8\n",
            "[ 194/1000] train_loss: 0.24657 valid_loss: 0.08191 \n",
            "patience: 9\n",
            "[ 195/1000] train_loss: 0.24491 valid_loss: 0.07633 \n",
            "patience: 10\n",
            "[ 196/1000] train_loss: 0.24341 valid_loss: 0.09785 \n",
            "patience: 11\n",
            "min_valid_loss: 0.07276605527327808\n",
            "[ 197/1000] train_loss: 0.24562 valid_loss: 0.07277 \n",
            "Saving Model...\n",
            "[ 198/1000] train_loss: 0.24549 valid_loss: 0.08964 \n",
            "patience: 1\n",
            "[ 199/1000] train_loss: 0.24458 valid_loss: 0.08033 \n",
            "patience: 2\n",
            "[ 200/1000] train_loss: 0.24567 valid_loss: 0.07599 \n",
            "patience: 3\n",
            "min_valid_loss: 0.07264019755294195\n",
            "[ 201/1000] train_loss: 0.24394 valid_loss: 0.07264 \n",
            "Saving Model...\n",
            "[ 202/1000] train_loss: 0.24626 valid_loss: 0.07294 \n",
            "patience: 1\n",
            "[ 203/1000] train_loss: 0.24606 valid_loss: 0.10157 \n",
            "patience: 2\n",
            "[ 204/1000] train_loss: 0.24560 valid_loss: 0.08581 \n",
            "patience: 3\n",
            "[ 205/1000] train_loss: 0.24468 valid_loss: 0.07430 \n",
            "patience: 4\n",
            "min_valid_loss: 0.0725854027277983\n",
            "[ 206/1000] train_loss: 0.24569 valid_loss: 0.07259 \n",
            "Saving Model...\n",
            "[ 207/1000] train_loss: 0.24652 valid_loss: 0.11369 \n",
            "patience: 1\n",
            "[ 208/1000] train_loss: 0.24701 valid_loss: 0.07446 \n",
            "patience: 2\n",
            "[ 209/1000] train_loss: 0.24738 valid_loss: 0.07589 \n",
            "patience: 3\n",
            "min_valid_loss: 0.0724884437959272\n",
            "[ 210/1000] train_loss: 0.24497 valid_loss: 0.07249 \n",
            "Saving Model...\n",
            "[ 211/1000] train_loss: 0.24917 valid_loss: 0.07249 \n",
            "patience: 1\n",
            "[ 212/1000] train_loss: 0.24483 valid_loss: 0.07546 \n",
            "patience: 2\n",
            "[ 213/1000] train_loss: 0.24503 valid_loss: 0.07578 \n",
            "patience: 3\n",
            "[ 214/1000] train_loss: 0.24344 valid_loss: 0.08886 \n",
            "patience: 4\n",
            "[ 215/1000] train_loss: 0.24508 valid_loss: 0.07915 \n",
            "patience: 5\n",
            "[ 216/1000] train_loss: 0.24374 valid_loss: 0.07814 \n",
            "patience: 6\n",
            "[ 217/1000] train_loss: 0.24545 valid_loss: 0.07495 \n",
            "patience: 7\n",
            "[ 218/1000] train_loss: 0.24382 valid_loss: 0.07841 \n",
            "patience: 8\n",
            "[ 219/1000] train_loss: 0.24578 valid_loss: 0.07533 \n",
            "patience: 9\n",
            "[ 220/1000] train_loss: 0.24339 valid_loss: 0.07472 \n",
            "patience: 10\n",
            "[ 221/1000] train_loss: 0.24453 valid_loss: 0.07476 \n",
            "patience: 11\n",
            "[ 222/1000] train_loss: 0.25017 valid_loss: 0.09583 \n",
            "patience: 12\n",
            "[ 223/1000] train_loss: 0.24932 valid_loss: 0.07270 \n",
            "patience: 13\n",
            "min_valid_loss: 0.07246003212692502\n",
            "[ 224/1000] train_loss: 0.24423 valid_loss: 0.07246 \n",
            "Saving Model...\n",
            "[ 225/1000] train_loss: 0.24433 valid_loss: 0.08820 \n",
            "patience: 1\n",
            "[ 226/1000] train_loss: 0.24325 valid_loss: 0.09038 \n",
            "patience: 2\n",
            "[ 227/1000] train_loss: 0.24442 valid_loss: 0.07604 \n",
            "patience: 3\n",
            "[ 228/1000] train_loss: 0.24486 valid_loss: 0.09709 \n",
            "patience: 4\n",
            "min_valid_loss: 0.07230334411383615\n",
            "[ 229/1000] train_loss: 0.24428 valid_loss: 0.07230 \n",
            "Saving Model...\n",
            "[ 230/1000] train_loss: 0.24260 valid_loss: 0.07267 \n",
            "patience: 1\n",
            "[ 231/1000] train_loss: 0.24207 valid_loss: 0.07741 \n",
            "patience: 2\n",
            "[ 232/1000] train_loss: 0.24441 valid_loss: 0.08267 \n",
            "patience: 3\n",
            "[ 233/1000] train_loss: 0.24423 valid_loss: 0.07959 \n",
            "patience: 4\n",
            "[ 234/1000] train_loss: 0.24465 valid_loss: 0.07634 \n",
            "patience: 5\n",
            "[ 235/1000] train_loss: 0.24104 valid_loss: 0.07672 \n",
            "patience: 6\n",
            "[ 236/1000] train_loss: 0.24535 valid_loss: 0.07423 \n",
            "patience: 7\n",
            "[ 237/1000] train_loss: 0.24449 valid_loss: 0.07268 \n",
            "patience: 8\n",
            "[ 238/1000] train_loss: 0.24492 valid_loss: 0.07974 \n",
            "patience: 9\n",
            "[ 239/1000] train_loss: 0.24114 valid_loss: 0.07276 \n",
            "patience: 10\n",
            "[ 240/1000] train_loss: 0.24308 valid_loss: 0.07300 \n",
            "patience: 11\n",
            "[ 241/1000] train_loss: 0.24353 valid_loss: 0.07233 \n",
            "patience: 12\n",
            "min_valid_loss: 0.0722070040919625\n",
            "[ 242/1000] train_loss: 0.24524 valid_loss: 0.07221 \n",
            "Saving Model...\n",
            "min_valid_loss: 0.07215463527612523\n",
            "[ 243/1000] train_loss: 0.24263 valid_loss: 0.07215 \n",
            "Saving Model...\n",
            "[ 244/1000] train_loss: 0.24405 valid_loss: 0.09202 \n",
            "patience: 1\n",
            "[ 245/1000] train_loss: 0.24519 valid_loss: 0.07331 \n",
            "patience: 2\n",
            "[ 246/1000] train_loss: 0.24195 valid_loss: 0.08138 \n",
            "patience: 3\n",
            "[ 247/1000] train_loss: 0.24449 valid_loss: 0.07322 \n",
            "patience: 4\n",
            "[ 248/1000] train_loss: 0.24587 valid_loss: 0.07696 \n",
            "patience: 5\n",
            "[ 249/1000] train_loss: 0.24373 valid_loss: 0.07868 \n",
            "patience: 6\n",
            "[ 250/1000] train_loss: 0.24349 valid_loss: 0.07261 \n",
            "patience: 7\n",
            "[ 251/1000] train_loss: 0.24117 valid_loss: 0.07820 \n",
            "patience: 8\n",
            "[ 252/1000] train_loss: 0.24216 valid_loss: 0.08718 \n",
            "patience: 9\n",
            "[ 253/1000] train_loss: 0.24514 valid_loss: 0.08185 \n",
            "patience: 10\n",
            "[ 254/1000] train_loss: 0.24587 valid_loss: 0.07235 \n",
            "patience: 11\n",
            "[ 255/1000] train_loss: 0.24050 valid_loss: 0.07437 \n",
            "patience: 12\n",
            "min_valid_loss: 0.07201046363853321\n",
            "[ 256/1000] train_loss: 0.24034 valid_loss: 0.07201 \n",
            "Saving Model...\n",
            "[ 257/1000] train_loss: 0.24769 valid_loss: 0.07243 \n",
            "patience: 1\n",
            "[ 258/1000] train_loss: 0.24163 valid_loss: 0.17736 \n",
            "patience: 2\n",
            "[ 259/1000] train_loss: 0.24281 valid_loss: 0.07605 \n",
            "patience: 3\n",
            "[ 260/1000] train_loss: 0.24226 valid_loss: 0.07843 \n",
            "patience: 4\n",
            "[ 261/1000] train_loss: 0.24603 valid_loss: 0.07263 \n",
            "patience: 5\n",
            "[ 262/1000] train_loss: 0.24438 valid_loss: 0.12962 \n",
            "patience: 6\n",
            "[ 263/1000] train_loss: 0.24184 valid_loss: 0.07532 \n",
            "patience: 7\n",
            "[ 264/1000] train_loss: 0.24384 valid_loss: 0.07783 \n",
            "patience: 8\n",
            "[ 265/1000] train_loss: 0.24291 valid_loss: 0.07544 \n",
            "patience: 9\n",
            "[ 266/1000] train_loss: 0.24483 valid_loss: 0.07215 \n",
            "patience: 10\n",
            "[ 267/1000] train_loss: 0.24421 valid_loss: 0.09269 \n",
            "patience: 11\n",
            "[ 268/1000] train_loss: 0.24299 valid_loss: 0.07261 \n",
            "patience: 12\n",
            "min_valid_loss: 0.07187252009270696\n",
            "[ 269/1000] train_loss: 0.24514 valid_loss: 0.07187 \n",
            "Saving Model...\n",
            "[ 270/1000] train_loss: 0.24118 valid_loss: 0.08510 \n",
            "patience: 1\n",
            "[ 271/1000] train_loss: 0.24181 valid_loss: 0.07423 \n",
            "patience: 2\n",
            "[ 272/1000] train_loss: 0.24149 valid_loss: 0.07331 \n",
            "patience: 3\n",
            "[ 273/1000] train_loss: 0.24266 valid_loss: 0.07204 \n",
            "patience: 4\n",
            "[ 274/1000] train_loss: 0.24421 valid_loss: 0.07230 \n",
            "patience: 5\n",
            "[ 275/1000] train_loss: 0.24500 valid_loss: 0.07299 \n",
            "patience: 6\n",
            "[ 276/1000] train_loss: 0.24267 valid_loss: 0.07670 \n",
            "patience: 7\n",
            "[ 277/1000] train_loss: 0.24299 valid_loss: 0.07377 \n",
            "patience: 8\n",
            "[ 278/1000] train_loss: 0.24351 valid_loss: 0.07478 \n",
            "patience: 9\n",
            "[ 279/1000] train_loss: 0.24272 valid_loss: 0.07621 \n",
            "patience: 10\n",
            "[ 280/1000] train_loss: 0.24100 valid_loss: 0.13085 \n",
            "patience: 11\n",
            "[ 281/1000] train_loss: 0.24064 valid_loss: 0.08256 \n",
            "patience: 12\n",
            "[ 282/1000] train_loss: 0.24130 valid_loss: 0.08360 \n",
            "patience: 13\n",
            "[ 283/1000] train_loss: 0.24545 valid_loss: 0.07202 \n",
            "patience: 14\n",
            "[ 284/1000] train_loss: 0.24198 valid_loss: 0.08693 \n",
            "patience: 15\n",
            "[ 285/1000] train_loss: 0.24095 valid_loss: 0.07529 \n",
            "patience: 16\n",
            "[ 286/1000] train_loss: 0.24218 valid_loss: 0.07319 \n",
            "patience: 17\n",
            "[ 287/1000] train_loss: 0.24214 valid_loss: 0.07798 \n",
            "patience: 18\n",
            "[ 288/1000] train_loss: 0.24482 valid_loss: 0.07311 \n",
            "patience: 19\n",
            "[ 289/1000] train_loss: 0.24265 valid_loss: 0.07528 \n",
            "patience: 20\n",
            "[ 290/1000] train_loss: 0.24181 valid_loss: 0.08059 \n",
            "patience: 21\n",
            "[ 291/1000] train_loss: 0.24306 valid_loss: 0.07360 \n",
            "patience: 22\n",
            "[ 292/1000] train_loss: 0.24195 valid_loss: 0.07614 \n",
            "patience: 23\n",
            "[ 293/1000] train_loss: 0.24110 valid_loss: 0.07402 \n",
            "patience: 24\n",
            "[ 294/1000] train_loss: 0.24016 valid_loss: 0.09075 \n",
            "patience: 25\n",
            "min_valid_loss: 0.07168896153552441\n",
            "[ 295/1000] train_loss: 0.23987 valid_loss: 0.07169 \n",
            "Saving Model...\n",
            "[ 296/1000] train_loss: 0.24329 valid_loss: 0.08211 \n",
            "patience: 1\n",
            "[ 297/1000] train_loss: 0.24196 valid_loss: 0.07955 \n",
            "patience: 2\n",
            "[ 298/1000] train_loss: 0.24123 valid_loss: 0.07995 \n",
            "patience: 3\n",
            "[ 299/1000] train_loss: 0.24074 valid_loss: 0.07416 \n",
            "patience: 4\n",
            "[ 300/1000] train_loss: 0.24154 valid_loss: 0.10901 \n",
            "patience: 5\n",
            "[ 301/1000] train_loss: 0.24040 valid_loss: 0.07269 \n",
            "patience: 6\n",
            "[ 302/1000] train_loss: 0.23988 valid_loss: 0.11269 \n",
            "patience: 7\n",
            "[ 303/1000] train_loss: 0.24144 valid_loss: 0.09133 \n",
            "patience: 8\n",
            "[ 304/1000] train_loss: 0.24159 valid_loss: 0.07195 \n",
            "patience: 9\n",
            "min_valid_loss: 0.07149313938141137\n",
            "[ 305/1000] train_loss: 0.24151 valid_loss: 0.07149 \n",
            "Saving Model...\n",
            "[ 306/1000] train_loss: 0.24143 valid_loss: 0.07214 \n",
            "patience: 1\n",
            "[ 307/1000] train_loss: 0.24159 valid_loss: 0.07811 \n",
            "patience: 2\n",
            "[ 308/1000] train_loss: 0.24142 valid_loss: 0.07264 \n",
            "patience: 3\n",
            "[ 309/1000] train_loss: 0.24071 valid_loss: 0.07933 \n",
            "patience: 4\n",
            "[ 310/1000] train_loss: 0.23919 valid_loss: 0.09717 \n",
            "patience: 5\n",
            "[ 311/1000] train_loss: 0.24226 valid_loss: 0.07182 \n",
            "patience: 6\n",
            "[ 312/1000] train_loss: 0.24453 valid_loss: 0.07468 \n",
            "patience: 7\n",
            "[ 313/1000] train_loss: 0.24211 valid_loss: 0.08578 \n",
            "patience: 8\n",
            "[ 314/1000] train_loss: 0.24296 valid_loss: 0.08113 \n",
            "patience: 9\n",
            "[ 315/1000] train_loss: 0.24184 valid_loss: 0.07201 \n",
            "patience: 10\n",
            "[ 316/1000] train_loss: 0.23958 valid_loss: 0.07992 \n",
            "patience: 11\n",
            "[ 317/1000] train_loss: 0.24010 valid_loss: 0.07161 \n",
            "patience: 12\n",
            "[ 318/1000] train_loss: 0.23870 valid_loss: 0.07157 \n",
            "patience: 13\n",
            "[ 319/1000] train_loss: 0.24350 valid_loss: 0.07388 \n",
            "patience: 14\n",
            "[ 320/1000] train_loss: 0.24052 valid_loss: 0.11185 \n",
            "patience: 15\n",
            "[ 321/1000] train_loss: 0.24287 valid_loss: 0.07668 \n",
            "patience: 16\n",
            "[ 322/1000] train_loss: 0.24026 valid_loss: 0.07248 \n",
            "patience: 17\n",
            "min_valid_loss: 0.07140454605666434\n",
            "[ 323/1000] train_loss: 0.24197 valid_loss: 0.07140 \n",
            "Saving Model...\n",
            "[ 324/1000] train_loss: 0.23976 valid_loss: 0.08364 \n",
            "patience: 1\n",
            "[ 325/1000] train_loss: 0.24307 valid_loss: 0.07728 \n",
            "patience: 2\n",
            "[ 326/1000] train_loss: 0.24115 valid_loss: 0.07332 \n",
            "patience: 3\n",
            "[ 327/1000] train_loss: 0.24168 valid_loss: 0.07865 \n",
            "patience: 4\n",
            "[ 328/1000] train_loss: 0.23872 valid_loss: 0.07630 \n",
            "patience: 5\n",
            "min_valid_loss: 0.0712834845280258\n",
            "[ 329/1000] train_loss: 0.24132 valid_loss: 0.07128 \n",
            "Saving Model...\n",
            "[ 330/1000] train_loss: 0.24148 valid_loss: 0.07324 \n",
            "patience: 1\n",
            "[ 331/1000] train_loss: 0.23925 valid_loss: 0.12488 \n",
            "patience: 2\n",
            "[ 332/1000] train_loss: 0.24070 valid_loss: 0.07179 \n",
            "patience: 3\n",
            "[ 333/1000] train_loss: 0.23877 valid_loss: 0.09165 \n",
            "patience: 4\n",
            "[ 334/1000] train_loss: 0.24019 valid_loss: 0.07787 \n",
            "patience: 5\n",
            "[ 335/1000] train_loss: 0.24163 valid_loss: 0.13425 \n",
            "patience: 6\n",
            "[ 336/1000] train_loss: 0.24336 valid_loss: 0.07846 \n",
            "patience: 7\n",
            "[ 337/1000] train_loss: 0.24079 valid_loss: 0.08174 \n",
            "patience: 8\n",
            "[ 338/1000] train_loss: 0.24154 valid_loss: 0.07133 \n",
            "patience: 9\n",
            "[ 339/1000] train_loss: 0.24068 valid_loss: 0.07437 \n",
            "patience: 10\n",
            "[ 340/1000] train_loss: 0.23912 valid_loss: 0.08184 \n",
            "patience: 11\n",
            "[ 341/1000] train_loss: 0.24116 valid_loss: 0.10536 \n",
            "patience: 12\n",
            "[ 342/1000] train_loss: 0.23913 valid_loss: 0.08298 \n",
            "patience: 13\n",
            "[ 343/1000] train_loss: 0.23940 valid_loss: 0.10613 \n",
            "patience: 14\n",
            "[ 344/1000] train_loss: 0.23954 valid_loss: 0.08007 \n",
            "patience: 15\n",
            "[ 345/1000] train_loss: 0.24005 valid_loss: 0.07284 \n",
            "patience: 16\n",
            "[ 346/1000] train_loss: 0.24112 valid_loss: 0.07445 \n",
            "patience: 17\n",
            "[ 347/1000] train_loss: 0.24039 valid_loss: 0.07550 \n",
            "patience: 18\n",
            "[ 348/1000] train_loss: 0.23925 valid_loss: 0.07142 \n",
            "patience: 19\n",
            "[ 349/1000] train_loss: 0.24240 valid_loss: 0.07582 \n",
            "patience: 20\n",
            "[ 350/1000] train_loss: 0.23935 valid_loss: 0.07399 \n",
            "patience: 21\n",
            "[ 351/1000] train_loss: 0.23881 valid_loss: 0.08091 \n",
            "patience: 22\n",
            "[ 352/1000] train_loss: 0.23995 valid_loss: 0.07205 \n",
            "patience: 23\n",
            "[ 353/1000] train_loss: 0.24076 valid_loss: 0.11016 \n",
            "patience: 24\n",
            "[ 354/1000] train_loss: 0.23898 valid_loss: 0.07435 \n",
            "patience: 25\n",
            "[ 355/1000] train_loss: 0.24008 valid_loss: 0.07133 \n",
            "patience: 26\n",
            "[ 356/1000] train_loss: 0.24209 valid_loss: 0.07254 \n",
            "patience: 27\n",
            "min_valid_loss: 0.07121328731394701\n",
            "[ 357/1000] train_loss: 0.24099 valid_loss: 0.07121 \n",
            "Saving Model...\n",
            "[ 358/1000] train_loss: 0.24099 valid_loss: 0.07242 \n",
            "patience: 1\n",
            "[ 359/1000] train_loss: 0.23628 valid_loss: 0.07669 \n",
            "patience: 2\n",
            "[ 360/1000] train_loss: 0.23887 valid_loss: 0.07802 \n",
            "patience: 3\n",
            "min_valid_loss: 0.07108519685681204\n",
            "[ 361/1000] train_loss: 0.23934 valid_loss: 0.07109 \n",
            "Saving Model...\n",
            "[ 362/1000] train_loss: 0.23984 valid_loss: 0.08860 \n",
            "patience: 1\n",
            "[ 363/1000] train_loss: 0.23764 valid_loss: 0.08807 \n",
            "patience: 2\n",
            "[ 364/1000] train_loss: 0.23871 valid_loss: 0.07197 \n",
            "patience: 3\n",
            "[ 365/1000] train_loss: 0.24074 valid_loss: 0.07915 \n",
            "patience: 4\n",
            "[ 366/1000] train_loss: 0.24032 valid_loss: 0.07372 \n",
            "patience: 5\n",
            "[ 367/1000] train_loss: 0.23739 valid_loss: 0.08462 \n",
            "patience: 6\n",
            "[ 368/1000] train_loss: 0.24053 valid_loss: 0.07290 \n",
            "patience: 7\n",
            "[ 369/1000] train_loss: 0.23891 valid_loss: 0.07883 \n",
            "patience: 8\n",
            "[ 370/1000] train_loss: 0.24188 valid_loss: 0.07469 \n",
            "patience: 9\n",
            "[ 371/1000] train_loss: 0.24005 valid_loss: 0.07180 \n",
            "patience: 10\n",
            "[ 372/1000] train_loss: 0.23686 valid_loss: 0.07282 \n",
            "patience: 11\n",
            "[ 373/1000] train_loss: 0.24040 valid_loss: 0.07290 \n",
            "patience: 12\n",
            "[ 374/1000] train_loss: 0.23964 valid_loss: 0.09382 \n",
            "patience: 13\n",
            "min_valid_loss: 0.07098817059703104\n",
            "[ 375/1000] train_loss: 0.24024 valid_loss: 0.07099 \n",
            "Saving Model...\n",
            "[ 376/1000] train_loss: 0.23982 valid_loss: 0.07358 \n",
            "patience: 1\n",
            "[ 377/1000] train_loss: 0.24090 valid_loss: 0.07999 \n",
            "patience: 2\n",
            "[ 378/1000] train_loss: 0.23866 valid_loss: 0.07959 \n",
            "patience: 3\n",
            "[ 379/1000] train_loss: 0.23692 valid_loss: 0.07151 \n",
            "patience: 4\n",
            "[ 380/1000] train_loss: 0.23832 valid_loss: 0.07125 \n",
            "patience: 5\n",
            "[ 381/1000] train_loss: 0.23897 valid_loss: 0.07131 \n",
            "patience: 6\n",
            "[ 382/1000] train_loss: 0.23754 valid_loss: 0.11161 \n",
            "patience: 7\n",
            "min_valid_loss: 0.07081710160626015\n",
            "[ 383/1000] train_loss: 0.24056 valid_loss: 0.07082 \n",
            "Saving Model...\n",
            "[ 384/1000] train_loss: 0.23981 valid_loss: 0.07466 \n",
            "patience: 1\n",
            "[ 385/1000] train_loss: 0.23932 valid_loss: 0.08042 \n",
            "patience: 2\n",
            "[ 386/1000] train_loss: 0.24199 valid_loss: 0.07268 \n",
            "patience: 3\n",
            "[ 387/1000] train_loss: 0.23876 valid_loss: 0.07084 \n",
            "patience: 4\n",
            "[ 388/1000] train_loss: 0.23822 valid_loss: 0.07545 \n",
            "patience: 5\n",
            "[ 389/1000] train_loss: 0.23782 valid_loss: 0.07730 \n",
            "patience: 6\n",
            "[ 390/1000] train_loss: 0.23861 valid_loss: 0.09454 \n",
            "patience: 7\n",
            "[ 391/1000] train_loss: 0.23940 valid_loss: 0.07097 \n",
            "patience: 8\n",
            "min_valid_loss: 0.07076674777603296\n",
            "[ 392/1000] train_loss: 0.24002 valid_loss: 0.07077 \n",
            "Saving Model...\n",
            "[ 393/1000] train_loss: 0.23814 valid_loss: 0.07087 \n",
            "patience: 1\n",
            "min_valid_loss: 0.0706063931103091\n",
            "[ 394/1000] train_loss: 0.24022 valid_loss: 0.07061 \n",
            "Saving Model...\n",
            "[ 395/1000] train_loss: 0.24154 valid_loss: 0.07311 \n",
            "patience: 1\n",
            "[ 396/1000] train_loss: 0.23787 valid_loss: 0.07456 \n",
            "patience: 2\n",
            "min_valid_loss: 0.07060199936533028\n",
            "[ 397/1000] train_loss: 0.24167 valid_loss: 0.07060 \n",
            "Saving Model...\n",
            "[ 398/1000] train_loss: 0.23860 valid_loss: 0.07078 \n",
            "patience: 1\n",
            "[ 399/1000] train_loss: 0.23991 valid_loss: 0.07177 \n",
            "patience: 2\n",
            "[ 400/1000] train_loss: 0.23675 valid_loss: 0.07507 \n",
            "patience: 3\n",
            "[ 401/1000] train_loss: 0.23749 valid_loss: 0.07067 \n",
            "patience: 4\n",
            "[ 402/1000] train_loss: 0.23752 valid_loss: 0.07322 \n",
            "patience: 5\n",
            "[ 403/1000] train_loss: 0.23676 valid_loss: 0.07320 \n",
            "patience: 6\n",
            "[ 404/1000] train_loss: 0.23798 valid_loss: 0.07673 \n",
            "patience: 7\n",
            "[ 405/1000] train_loss: 0.23770 valid_loss: 0.07748 \n",
            "patience: 8\n",
            "[ 406/1000] train_loss: 0.24057 valid_loss: 0.07065 \n",
            "patience: 9\n",
            "[ 407/1000] train_loss: 0.23673 valid_loss: 0.10228 \n",
            "patience: 10\n",
            "[ 408/1000] train_loss: 0.23917 valid_loss: 0.07695 \n",
            "patience: 11\n",
            "[ 409/1000] train_loss: 0.23928 valid_loss: 0.07080 \n",
            "patience: 12\n",
            "[ 410/1000] train_loss: 0.23718 valid_loss: 0.07076 \n",
            "patience: 13\n",
            "[ 411/1000] train_loss: 0.23653 valid_loss: 0.09064 \n",
            "patience: 14\n",
            "[ 412/1000] train_loss: 0.23897 valid_loss: 0.07072 \n",
            "patience: 15\n",
            "[ 413/1000] train_loss: 0.23534 valid_loss: 0.09508 \n",
            "patience: 16\n",
            "min_valid_loss: 0.07051442212400001\n",
            "[ 414/1000] train_loss: 0.23716 valid_loss: 0.07051 \n",
            "Saving Model...\n",
            "[ 415/1000] train_loss: 0.23980 valid_loss: 0.07125 \n",
            "patience: 1\n",
            "[ 416/1000] train_loss: 0.23924 valid_loss: 0.07133 \n",
            "patience: 2\n",
            "[ 417/1000] train_loss: 0.23785 valid_loss: 0.08623 \n",
            "patience: 3\n",
            "[ 418/1000] train_loss: 0.23741 valid_loss: 0.07406 \n",
            "patience: 4\n",
            "[ 419/1000] train_loss: 0.23694 valid_loss: 0.07094 \n",
            "patience: 5\n",
            "[ 420/1000] train_loss: 0.23509 valid_loss: 0.07914 \n",
            "patience: 6\n",
            "[ 421/1000] train_loss: 0.23720 valid_loss: 0.07474 \n",
            "patience: 7\n",
            "[ 422/1000] train_loss: 0.23590 valid_loss: 0.07126 \n",
            "patience: 8\n",
            "[ 423/1000] train_loss: 0.23852 valid_loss: 0.07578 \n",
            "patience: 9\n",
            "[ 424/1000] train_loss: 0.23539 valid_loss: 0.07430 \n",
            "patience: 10\n",
            "[ 425/1000] train_loss: 0.23543 valid_loss: 0.07441 \n",
            "patience: 11\n",
            "[ 426/1000] train_loss: 0.23827 valid_loss: 0.07494 \n",
            "patience: 12\n",
            "[ 427/1000] train_loss: 0.23811 valid_loss: 0.07115 \n",
            "patience: 13\n",
            "[ 428/1000] train_loss: 0.23759 valid_loss: 0.07098 \n",
            "patience: 14\n",
            "[ 429/1000] train_loss: 0.23684 valid_loss: 0.08465 \n",
            "patience: 15\n",
            "[ 430/1000] train_loss: 0.23761 valid_loss: 0.07553 \n",
            "patience: 16\n",
            "[ 431/1000] train_loss: 0.23616 valid_loss: 0.07332 \n",
            "patience: 17\n",
            "[ 432/1000] train_loss: 0.23747 valid_loss: 0.07488 \n",
            "patience: 18\n",
            "[ 433/1000] train_loss: 0.23727 valid_loss: 0.07229 \n",
            "patience: 19\n",
            "[ 434/1000] train_loss: 0.23609 valid_loss: 0.07978 \n",
            "patience: 20\n",
            "[ 435/1000] train_loss: 0.23658 valid_loss: 0.07850 \n",
            "patience: 21\n",
            "[ 436/1000] train_loss: 0.23522 valid_loss: 0.07276 \n",
            "patience: 22\n",
            "[ 437/1000] train_loss: 0.23703 valid_loss: 0.07228 \n",
            "patience: 23\n",
            "[ 438/1000] train_loss: 0.23556 valid_loss: 0.07219 \n",
            "patience: 24\n",
            "[ 439/1000] train_loss: 0.23934 valid_loss: 0.11688 \n",
            "patience: 25\n",
            "min_valid_loss: 0.07044296468784278\n",
            "[ 440/1000] train_loss: 0.23691 valid_loss: 0.07044 \n",
            "Saving Model...\n",
            "min_valid_loss: 0.07025322194320259\n",
            "[ 441/1000] train_loss: 0.23832 valid_loss: 0.07025 \n",
            "Saving Model...\n",
            "[ 442/1000] train_loss: 0.23707 valid_loss: 0.07437 \n",
            "patience: 1\n",
            "[ 443/1000] train_loss: 0.23553 valid_loss: 0.07043 \n",
            "patience: 2\n",
            "[ 444/1000] train_loss: 0.23821 valid_loss: 0.07033 \n",
            "patience: 3\n",
            "[ 445/1000] train_loss: 0.23681 valid_loss: 0.07267 \n",
            "patience: 4\n",
            "[ 446/1000] train_loss: 0.23692 valid_loss: 0.07163 \n",
            "patience: 5\n",
            "[ 447/1000] train_loss: 0.23808 valid_loss: 0.07069 \n",
            "patience: 6\n",
            "[ 448/1000] train_loss: 0.23715 valid_loss: 0.07052 \n",
            "patience: 7\n",
            "[ 449/1000] train_loss: 0.23543 valid_loss: 0.08311 \n",
            "patience: 8\n",
            "min_valid_loss: 0.07020282045610853\n",
            "[ 450/1000] train_loss: 0.23635 valid_loss: 0.07020 \n",
            "Saving Model...\n",
            "[ 451/1000] train_loss: 0.24043 valid_loss: 0.07311 \n",
            "patience: 1\n",
            "[ 452/1000] train_loss: 0.23823 valid_loss: 0.08888 \n",
            "patience: 2\n",
            "[ 453/1000] train_loss: 0.23510 valid_loss: 0.07105 \n",
            "patience: 3\n",
            "[ 454/1000] train_loss: 0.23555 valid_loss: 0.07505 \n",
            "patience: 4\n",
            "[ 455/1000] train_loss: 0.23463 valid_loss: 0.07853 \n",
            "patience: 5\n",
            "[ 456/1000] train_loss: 0.23739 valid_loss: 0.07185 \n",
            "patience: 6\n",
            "[ 457/1000] train_loss: 0.23830 valid_loss: 0.07765 \n",
            "patience: 7\n",
            "[ 458/1000] train_loss: 0.23931 valid_loss: 0.07413 \n",
            "patience: 8\n",
            "[ 459/1000] train_loss: 0.23467 valid_loss: 0.07207 \n",
            "patience: 9\n",
            "[ 460/1000] train_loss: 0.23584 valid_loss: 0.07632 \n",
            "patience: 10\n",
            "[ 461/1000] train_loss: 0.23461 valid_loss: 0.07454 \n",
            "patience: 11\n",
            "[ 462/1000] train_loss: 0.23640 valid_loss: 0.07210 \n",
            "patience: 12\n",
            "[ 463/1000] train_loss: 0.23706 valid_loss: 0.08388 \n",
            "patience: 13\n",
            "[ 464/1000] train_loss: 0.23642 valid_loss: 0.07073 \n",
            "patience: 14\n",
            "[ 465/1000] train_loss: 0.23606 valid_loss: 0.08045 \n",
            "patience: 15\n",
            "[ 466/1000] train_loss: 0.23910 valid_loss: 0.07204 \n",
            "patience: 16\n",
            "[ 467/1000] train_loss: 0.23714 valid_loss: 0.07258 \n",
            "patience: 17\n",
            "[ 468/1000] train_loss: 0.23722 valid_loss: 0.07832 \n",
            "patience: 18\n",
            "[ 469/1000] train_loss: 0.23537 valid_loss: 0.07027 \n",
            "patience: 19\n",
            "[ 470/1000] train_loss: 0.23525 valid_loss: 0.07326 \n",
            "patience: 20\n",
            "[ 471/1000] train_loss: 0.23677 valid_loss: 0.07505 \n",
            "patience: 21\n",
            "[ 472/1000] train_loss: 0.23617 valid_loss: 0.08139 \n",
            "patience: 22\n",
            "[ 473/1000] train_loss: 0.23795 valid_loss: 0.09188 \n",
            "patience: 23\n",
            "[ 474/1000] train_loss: 0.24059 valid_loss: 0.08371 \n",
            "patience: 24\n",
            "[ 475/1000] train_loss: 0.23446 valid_loss: 0.07708 \n",
            "patience: 25\n",
            "[ 476/1000] train_loss: 0.23858 valid_loss: 0.07326 \n",
            "patience: 26\n",
            "[ 477/1000] train_loss: 0.23316 valid_loss: 0.07236 \n",
            "patience: 27\n",
            "min_valid_loss: 0.07009618559869023\n",
            "[ 478/1000] train_loss: 0.23491 valid_loss: 0.07010 \n",
            "Saving Model...\n",
            "[ 479/1000] train_loss: 0.23453 valid_loss: 0.07277 \n",
            "patience: 1\n",
            "min_valid_loss: 0.06999652369602306\n",
            "[ 480/1000] train_loss: 0.23708 valid_loss: 0.07000 \n",
            "Saving Model...\n",
            "[ 481/1000] train_loss: 0.23581 valid_loss: 0.08437 \n",
            "patience: 1\n",
            "[ 482/1000] train_loss: 0.23498 valid_loss: 0.07029 \n",
            "patience: 2\n",
            "[ 483/1000] train_loss: 0.23506 valid_loss: 0.07087 \n",
            "patience: 3\n",
            "[ 484/1000] train_loss: 0.23493 valid_loss: 0.08524 \n",
            "patience: 4\n",
            "[ 485/1000] train_loss: 0.23401 valid_loss: 0.07423 \n",
            "patience: 5\n",
            "[ 486/1000] train_loss: 0.23357 valid_loss: 0.07417 \n",
            "patience: 6\n",
            "[ 487/1000] train_loss: 0.23576 valid_loss: 0.07078 \n",
            "patience: 7\n",
            "[ 488/1000] train_loss: 0.23420 valid_loss: 0.07597 \n",
            "patience: 8\n",
            "[ 489/1000] train_loss: 0.23753 valid_loss: 0.10402 \n",
            "patience: 9\n",
            "[ 490/1000] train_loss: 0.23450 valid_loss: 0.07275 \n",
            "patience: 10\n",
            "[ 491/1000] train_loss: 0.23577 valid_loss: 0.07105 \n",
            "patience: 11\n",
            "[ 492/1000] train_loss: 0.23527 valid_loss: 0.07227 \n",
            "patience: 12\n",
            "[ 493/1000] train_loss: 0.23463 valid_loss: 0.07014 \n",
            "patience: 13\n",
            "[ 494/1000] train_loss: 0.23528 valid_loss: 0.07070 \n",
            "patience: 14\n",
            "[ 495/1000] train_loss: 0.23487 valid_loss: 0.09646 \n",
            "patience: 15\n",
            "[ 496/1000] train_loss: 0.23603 valid_loss: 0.09885 \n",
            "patience: 16\n",
            "[ 497/1000] train_loss: 0.23367 valid_loss: 0.07240 \n",
            "patience: 17\n",
            "[ 498/1000] train_loss: 0.23557 valid_loss: 0.07029 \n",
            "patience: 18\n",
            "[ 499/1000] train_loss: 0.23461 valid_loss: 0.07638 \n",
            "patience: 19\n",
            "[ 500/1000] train_loss: 0.23458 valid_loss: 0.07849 \n",
            "patience: 20\n",
            "[ 501/1000] train_loss: 0.23451 valid_loss: 0.07052 \n",
            "patience: 21\n",
            "[ 502/1000] train_loss: 0.23909 valid_loss: 0.07144 \n",
            "patience: 22\n",
            "min_valid_loss: 0.0699277635839944\n",
            "[ 503/1000] train_loss: 0.23192 valid_loss: 0.06993 \n",
            "Saving Model...\n",
            "[ 504/1000] train_loss: 0.23343 valid_loss: 0.07033 \n",
            "patience: 1\n",
            "[ 505/1000] train_loss: 0.23705 valid_loss: 0.07263 \n",
            "patience: 2\n",
            "[ 506/1000] train_loss: 0.23564 valid_loss: 0.07696 \n",
            "patience: 3\n",
            "[ 507/1000] train_loss: 0.23645 valid_loss: 0.07387 \n",
            "patience: 4\n",
            "min_valid_loss: 0.06990105977391002\n",
            "[ 508/1000] train_loss: 0.23359 valid_loss: 0.06990 \n",
            "Saving Model...\n",
            "[ 509/1000] train_loss: 0.23323 valid_loss: 0.11756 \n",
            "patience: 1\n",
            "[ 510/1000] train_loss: 0.23515 valid_loss: 0.09076 \n",
            "patience: 2\n",
            "[ 511/1000] train_loss: 0.23538 valid_loss: 0.07378 \n",
            "patience: 3\n",
            "[ 512/1000] train_loss: 0.23370 valid_loss: 0.09212 \n",
            "patience: 4\n",
            "[ 513/1000] train_loss: 0.23587 valid_loss: 0.07294 \n",
            "patience: 5\n",
            "[ 514/1000] train_loss: 0.23913 valid_loss: 0.07109 \n",
            "patience: 6\n",
            "[ 515/1000] train_loss: 0.23688 valid_loss: 0.07308 \n",
            "patience: 7\n",
            "[ 516/1000] train_loss: 0.23452 valid_loss: 0.07039 \n",
            "patience: 8\n",
            "[ 517/1000] train_loss: 0.23322 valid_loss: 0.07779 \n",
            "patience: 9\n",
            "[ 518/1000] train_loss: 0.24034 valid_loss: 0.08828 \n",
            "patience: 10\n",
            "[ 519/1000] train_loss: 0.23832 valid_loss: 0.09840 \n",
            "patience: 11\n",
            "min_valid_loss: 0.06965109526792222\n",
            "[ 520/1000] train_loss: 0.23252 valid_loss: 0.06965 \n",
            "Saving Model...\n",
            "[ 521/1000] train_loss: 0.23638 valid_loss: 0.07444 \n",
            "patience: 1\n",
            "[ 522/1000] train_loss: 0.23365 valid_loss: 0.06976 \n",
            "patience: 2\n",
            "[ 523/1000] train_loss: 0.23339 valid_loss: 0.07093 \n",
            "patience: 3\n",
            "[ 524/1000] train_loss: 0.23583 valid_loss: 0.08159 \n",
            "patience: 4\n",
            "[ 525/1000] train_loss: 0.23451 valid_loss: 0.07017 \n",
            "patience: 5\n",
            "[ 526/1000] train_loss: 0.23531 valid_loss: 0.07169 \n",
            "patience: 6\n",
            "[ 527/1000] train_loss: 0.23268 valid_loss: 0.09092 \n",
            "patience: 7\n",
            "[ 528/1000] train_loss: 0.23467 valid_loss: 0.07170 \n",
            "patience: 8\n",
            "[ 529/1000] train_loss: 0.23397 valid_loss: 0.07543 \n",
            "patience: 9\n",
            "[ 530/1000] train_loss: 0.23503 valid_loss: 0.08578 \n",
            "patience: 10\n",
            "[ 531/1000] train_loss: 0.23432 valid_loss: 0.07015 \n",
            "patience: 11\n",
            "[ 532/1000] train_loss: 0.23293 valid_loss: 0.10943 \n",
            "patience: 12\n",
            "[ 533/1000] train_loss: 0.23500 valid_loss: 0.09436 \n",
            "patience: 13\n",
            "[ 534/1000] train_loss: 0.23594 valid_loss: 0.06994 \n",
            "patience: 14\n",
            "[ 535/1000] train_loss: 0.23341 valid_loss: 0.07037 \n",
            "patience: 15\n",
            "[ 536/1000] train_loss: 0.23303 valid_loss: 0.07159 \n",
            "patience: 16\n",
            "[ 537/1000] train_loss: 0.23644 valid_loss: 0.07378 \n",
            "patience: 17\n",
            "[ 538/1000] train_loss: 0.23543 valid_loss: 0.07333 \n",
            "patience: 18\n",
            "[ 539/1000] train_loss: 0.23277 valid_loss: 0.07904 \n",
            "patience: 19\n",
            "[ 540/1000] train_loss: 0.23380 valid_loss: 0.06974 \n",
            "patience: 20\n",
            "[ 541/1000] train_loss: 0.23333 valid_loss: 0.07449 \n",
            "patience: 21\n",
            "[ 542/1000] train_loss: 0.23129 valid_loss: 0.07577 \n",
            "patience: 22\n",
            "[ 543/1000] train_loss: 0.23468 valid_loss: 0.07127 \n",
            "patience: 23\n",
            "[ 544/1000] train_loss: 0.23310 valid_loss: 0.09269 \n",
            "patience: 24\n",
            "[ 545/1000] train_loss: 0.23344 valid_loss: 0.07449 \n",
            "patience: 25\n",
            "[ 546/1000] train_loss: 0.23294 valid_loss: 0.07359 \n",
            "patience: 26\n",
            "[ 547/1000] train_loss: 0.23383 valid_loss: 0.07543 \n",
            "patience: 27\n",
            "[ 548/1000] train_loss: 0.23306 valid_loss: 0.07694 \n",
            "patience: 28\n",
            "[ 549/1000] train_loss: 0.23462 valid_loss: 0.07268 \n",
            "patience: 29\n",
            "[ 550/1000] train_loss: 0.23345 valid_loss: 0.09422 \n",
            "patience: 30\n",
            "Early stopping\n"
          ]
        }
      ],
      "source": [
        "humi_predict_model = train_model(humiModel, patience=30, num_epochs=1000,\n",
        "                                 train_loader=humi_trainloader,\n",
        "                                 valid_loader=humi_validloader)\n",
        "torch.save(humi_predict_model.state_dict(), \"humi_predict.pt\")"
      ],
      "id": "PT48wdZoxLOq"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pq-W2VDxLOq"
      },
      "source": [
        "### ONNX Coversion"
      ],
      "id": "2pq-W2VDxLOq"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "c64233ee",
      "metadata": {
        "id": "c64233ee"
      },
      "outputs": [],
      "source": [
        "def convert_to_onnx(saved_file_name):\n",
        "    saved_model = SimpleModel()\n",
        "    saved_model.load_state_dict(torch.load(saved_file_name))\n",
        "    saved_model.eval()\n",
        "    torch.onnx.export(\n",
        "        saved_model,\n",
        "        torch.randn((1, 3, 1)),\n",
        "        saved_file_name[:-3] + '.onnx',\n",
        "        opset_version=11,\n",
        "        do_constant_folding=True,\n",
        "        input_names=[\"input\"],\n",
        "        output_names=[\"output\"]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "pQWPJuN3xLOr"
      },
      "outputs": [],
      "source": [
        "convert_to_onnx(\"temp_predict.pt\")\n",
        "convert_to_onnx(\"humi_predict.pt\")"
      ],
      "id": "pQWPJuN3xLOr"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "980f3ab3",
      "metadata": {
        "id": "980f3ab3"
      },
      "outputs": [],
      "source": [
        "# End of Document."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s2819TPoErPP"
      },
      "id": "s2819TPoErPP",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}